#!/bin/bash

# 定义颜色
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

echo -e "${GREEN}=============================================${NC}"
echo -e "${GREEN}   Linux TCP 极致优化 & BBR 一键配置脚本      ${NC}"
echo -e "${GREEN}=============================================${NC}"

# 1. 检查 Root 权限
if [[ $EUID -ne 0 ]]; then
   echo -e "${RED}错误: 请使用 root 用户运行此脚本。${NC}"
   exit 1
fi

# 2. 检查内核版本 (BBR 需要 Kernel 4.9+)
KERNEL_VERSION=$(uname -r | cut -d- -f1)
MAJOR_VER=$(echo $KERNEL_VERSION | cut -d. -f1)
MINOR_VER=$(echo $KERNEL_VERSION | cut -d. -f2)

echo -e "${YELLOW}检测内核版本: $KERNEL_VERSION${NC}"

if [ "$MAJOR_VER" -lt 4 ] || ([ "$MAJOR_VER" -eq 4 ] && [ "$MINOR_VER" -lt 9 ]); then
    echo -e "${RED}[错误] 您的内核版本过低 (< 4.9)，无法开启 BBR。${NC}"
    echo -e "请先升级内核 (推荐升级到 Kernel 5.x 或 6.x)。"
    echo -e "CentOS 7 用户可搜索 'elrepo' 升级内核。"
    exit 1
fi

# 3. 备份现有配置
echo -e "${YELLOW}正在备份 /etc/sysctl.conf...${NC}"
cp /etc/sysctl.conf /etc/sysctl.conf.bak.$(date +%F-%H%M%S)

# 4. 清理旧参数 (防止重复追加导致报错或不生效)
# 定义我们要修改的参数列表
PARAMS=(
    "net.core.default_qdisc"
    "net.ipv4.tcp_congestion_control"
    "net.core.rmem_max"
    "net.core.wmem_max"
    "net.ipv4.tcp_rmem"
    "net.ipv4.tcp_wmem"
    "net.core.somaxconn"
    "net.ipv4.tcp_max_syn_backlog"
    "net.ipv4.tcp_fin_timeout"
    "net.ipv4.tcp_window_scaling"
    "net.ipv4.tcp_slow_start_after_idle"
    "net.ipv4.tcp_mtu_probing"
    "net.ipv4.tcp_reordering"
)

echo -e "${YELLOW}正在清理旧的 TCP 参数...${NC}"
for param in "${PARAMS[@]}"; do
    # 使用 sed 删除以该参数开头的行
    sed -i "/^$param/d" /etc/sysctl.conf
done

# 5. 写入新配置
echo -e "${YELLOW}正在写入深度优化参数...${NC}"

cat <<EOF >> /etc/sysctl.conf

# ==========================================
# TCP 性能优化 - 降低重传 & 提升吞吐
# (Generated by BitsFlowCloud Optimizer)
# ==========================================

# 1. 开启 BBR
net.core.default_qdisc = fq
net.ipv4.tcp_congestion_control = bbr

# 2. 增大 TCP 缓冲区 (针对 1G-10G 端口优化)
# 允许的最大接收/发送缓冲区 (单位: 字节, 32MB)
net.core.rmem_max = 33554432
net.core.wmem_max = 33554432
# TCP 自动调整缓冲区的范围 (最小 默认 最大)
net.ipv4.tcp_rmem = 4096 87380 33554432
net.ipv4.tcp_wmem = 4096 16384 33554432

# 3. 增加并发连接处理能力
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535

# 4. 优化连接保持和回收
# 减少 FIN_WAIT2 等待时间
net.ipv4.tcp_fin_timeout = 30
# 开启 TCP 窗口缩放 (必须开启，否则跑不满带宽)
net.ipv4.tcp_window_scaling = 1
# 禁用慢启动空闲重启 (防止闲置一会后速度掉下来)
net.ipv4.tcp_slow_start_after_idle = 0

# 5. 防丢包优化
# 开启 MTU 探测 (解决部分路由 MTU 问题导致的丢包)
net.ipv4.tcp_mtu_probing = 1
# 允许更多的无序数据包 (减少不必要的重传)
net.ipv4.tcp_reordering = 3
EOF

# 6. 应用配置
echo -e "${YELLOW}正在应用配置 (sysctl -p)...${NC}"
sysctl -p

# 7. 验证结果
BBR_STATUS=$(sysctl net.ipv4.tcp_congestion_control | awk '{print $3}')
QDISC_STATUS=$(sysctl net.core.default_qdisc | awk '{print $3}')

echo -e ""
echo -e "${GREEN}=============================================${NC}"
echo -e "${GREEN}   优化完成！状态检查：                       ${NC}"
echo -e "${GREEN}=============================================${NC}"

if [[ "$BBR_STATUS" == "bbr" ]] && [[ "$QDISC_STATUS" == "fq" ]]; then
    echo -e "TCP 拥塞控制: ${GREEN}$BBR_STATUS${NC}"
    echo -e "队列调度算法: ${GREEN}$QDISC_STATUS${NC}"
    echo -e "${GREEN}SUCCESS: BBR 已成功开启且参数已应用！${NC}"
else
    echo -e "TCP 拥塞控制: ${RED}$BBR_STATUS${NC}"
    echo -e "队列调度算法: ${RED}$QDISC_STATUS${NC}"
    echo -e "${RED}WARNING: BBR 似乎未正确开启，请检查内核是否支持。${NC}"
fi

echo -e "重传优化参数已加载。"
